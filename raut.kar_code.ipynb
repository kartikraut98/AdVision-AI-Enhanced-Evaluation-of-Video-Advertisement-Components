{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "072ba930",
   "metadata": {},
   "source": [
    "# AdVision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e92eb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb729d2ade03461fab9fb136b90d4719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yesit\\anaconda3\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer, BartForConditionalGeneration, BartTokenizer, pipeline\n",
    "import torch\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, accuracy_score,\n",
    "                             confusion_matrix, matthews_corrcoef)\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4716c0d7",
   "metadata": {},
   "source": [
    "## Part 1: Processing and extracting frames from the videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37950868",
   "metadata": {},
   "source": [
    "Extracts 50 evenly spaced frames from each video file in a specified directory. It defines a function, extract_frames, which reads a video file, calculates the frame interval, and captures frames at regular intervals. The main script iterates through all .mp4 video files in a given directory, calls this function to extract frames, and then saves these frames as PNG images in a new subdirectory named after the video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b73f1fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 50 frames from 1471363.mp4\n",
      "Extracted 50 frames from 1488315.mp4\n",
      "Extracted 50 frames from 1526213.mp4\n",
      "Extracted 50 frames from 1548815.mp4\n",
      "Extracted 50 frames from 1624211.mp4\n",
      "Extracted 50 frames from 1625396.mp4\n",
      "Extracted 50 frames from 1641167.mp4\n",
      "Extracted 50 frames from 1661301.mp4\n",
      "Extracted 50 frames from 1667694.mp4\n",
      "Extracted 50 frames from 1671240.mp4\n",
      "Extracted 50 frames from 1671980.mp4\n",
      "Extracted 50 frames from 1676138.mp4\n",
      "Extracted 50 frames from 1678735.mp4\n",
      "Extracted 50 frames from 1683011.mp4\n",
      "Extracted 50 frames from 1696112.mp4\n",
      "Extracted 50 frames from 1702594.mp4\n",
      "Extracted 50 frames from 1702851.mp4\n",
      "Extracted 50 frames from 1707220.mp4\n",
      "Extracted 50 frames from 1708967.mp4\n",
      "Extracted 50 frames from 1710855.mp4\n",
      "Extracted 50 frames from 1710993.mp4\n",
      "Extracted 50 frames from 1713794.mp4\n",
      "Extracted 50 frames from 1723501.mp4\n",
      "Extracted 50 frames from 1733728.mp4\n",
      "Extracted 50 frames from 1739116.mp4\n",
      "Extracted 50 frames from 1742915.mp4\n",
      "Extracted 50 frames from 1744482.mp4\n",
      "Extracted 50 frames from 1747914.mp4\n",
      "Extracted 50 frames from 1749291.mp4\n",
      "Extracted 50 frames from 1768584.mp4\n",
      "Extracted 50 frames from 1776082.mp4\n",
      "Extracted 50 frames from 1788954.mp4\n",
      "Extracted 50 frames from 1825984.mp4\n",
      "Extracted 50 frames from 1913310.mp4\n",
      "Extracted 50 frames from 1913929.mp4\n",
      "Extracted 50 frames from 1930720.mp4\n",
      "Extracted 50 frames from 1934234.mp4\n",
      "Extracted 50 frames from 1942611.mp4\n",
      "Extracted 50 frames from 1942695.mp4\n",
      "Extracted 50 frames from 1951792.mp4\n",
      "Extracted 50 frames from 1958530.mp4\n",
      "Extracted 50 frames from 1958838.mp4\n",
      "Extracted 50 frames from 1959692.mp4\n",
      "Extracted 50 frames from 1963503.mp4\n",
      "Extracted 50 frames from 1986629.mp4\n",
      "Extracted 50 frames from 1991222.mp4\n",
      "Extracted 50 frames from 2002557.mp4\n",
      "Extracted 50 frames from 2009582.mp4\n",
      "Extracted 50 frames from 2032457.mp4\n",
      "Extracted 50 frames from 2076630.mp4\n",
      "Extracted 50 frames from 2090919.mp4\n",
      "Extracted 50 frames from 2142915.mp4\n",
      "Extracted 50 frames from 2149098.mp4\n",
      "Extracted 50 frames from 2150923.mp4\n",
      "Extracted 50 frames from 2160345.mp4\n",
      "Extracted 50 frames from 2188255.mp4\n",
      "Extracted 50 frames from 2194673.mp4\n",
      "Extracted 50 frames from 2205093.mp4\n",
      "Extracted 50 frames from 2218186.mp4\n",
      "Extracted 50 frames from 2220795.mp4\n",
      "Extracted 50 frames from 2238004.mp4\n",
      "Extracted 50 frames from 2259242.mp4\n",
      "Extracted 50 frames from 2270982.mp4\n",
      "Extracted 50 frames from 2293300.mp4\n",
      "Extracted 50 frames from 2314704.mp4\n",
      "Extracted 50 frames from 2327598.mp4\n",
      "Extracted 50 frames from 2327954.mp4\n",
      "Extracted 50 frames from 2332208.mp4\n",
      "Extracted 50 frames from 2337786.mp4\n",
      "Extracted 50 frames from 2352149.mp4\n",
      "Extracted 50 frames from 2377805.mp4\n",
      "Extracted 50 frames from 2379465.mp4\n",
      "Extracted 50 frames from 2381477.mp4\n",
      "Extracted 50 frames from 2385082.mp4\n",
      "Extracted 50 frames from 2391348.mp4\n",
      "Extracted 50 frames from 2407070.mp4\n",
      "Extracted 50 frames from 2418354.mp4\n",
      "Extracted 50 frames from 2454123.mp4\n",
      "Extracted 50 frames from 2466835.mp4\n",
      "Extracted 50 frames from 2468277.mp4\n",
      "Extracted 50 frames from 2488408.mp4\n",
      "Extracted 50 frames from 2505712.mp4\n",
      "Extracted 50 frames from 2505718.mp4\n",
      "Extracted 50 frames from 2506189.mp4\n",
      "Extracted 50 frames from 2507887.mp4\n",
      "Extracted 50 frames from 2511206.mp4\n",
      "Extracted 50 frames from 2513974.mp4\n",
      "Extracted 50 frames from 2520568.mp4\n",
      "Extracted 50 frames from 2529687.mp4\n",
      "Extracted 50 frames from 2530396.mp4\n",
      "Extracted 50 frames from 2540988.mp4\n",
      "Extracted 50 frames from 2544459.mp4\n",
      "Extracted 50 frames from 2548638.mp4\n",
      "Extracted 50 frames from 2558982.mp4\n",
      "Extracted 50 frames from 2592911.mp4\n",
      "Extracted 50 frames from 2595709.mp4\n",
      "Extracted 50 frames from 2597996.mp4\n",
      "Extracted 50 frames from 2612386.mp4\n",
      "Extracted 50 frames from 2620437.mp4\n",
      "Extracted 50 frames from 2650588.mp4\n",
      "Extracted 50 frames from 2652509.mp4\n",
      "Extracted 50 frames from 2710205.mp4\n",
      "Extracted 50 frames from 2714373.mp4\n",
      "Extracted 50 frames from 2716616.mp4\n",
      "Extracted 50 frames from 2750416.mp4\n",
      "Extracted 50 frames from 2755227.mp4\n",
      "Extracted 50 frames from 2764983.mp4\n",
      "Extracted 50 frames from 2789795.mp4\n",
      "Extracted 50 frames from 2807978.mp4\n",
      "Extracted 50 frames from 2808275.mp4\n",
      "Extracted 50 frames from 2821872.mp4\n",
      "Extracted 50 frames from 2853933.mp4\n",
      "Extracted 50 frames from 2892458.mp4\n",
      "Extracted 50 frames from 2917037.mp4\n",
      "Extracted 50 frames from 2953810.mp4\n",
      "Extracted 50 frames from 2962688.mp4\n",
      "Extracted 50 frames from 3004458.mp4\n",
      "Extracted 50 frames from 3019128.mp4\n",
      "Extracted 50 frames from 3037506.mp4\n",
      "Extracted 50 frames from 3059869.mp4\n",
      "Extracted 50 frames from 3066063.mp4\n",
      "Extracted 50 frames from 3078623.mp4\n",
      "Extracted 50 frames from 3081313.mp4\n",
      "Extracted 50 frames from 3111684.mp4\n",
      "Extracted 50 frames from 3117116.mp4\n",
      "Extracted 50 frames from 3119347.mp4\n",
      "Extracted 50 frames from 3124938.mp4\n",
      "Extracted 50 frames from 3149347.mp4\n",
      "Extracted 50 frames from 3156128.mp4\n",
      "Extracted 50 frames from 3168530.mp4\n",
      "Extracted 50 frames from 3170124.mp4\n",
      "Extracted 50 frames from 3187482.mp4\n",
      "Extracted 50 frames from 3209706.mp4\n",
      "Extracted 50 frames from 3212463.mp4\n",
      "Extracted 50 frames from 3264190.mp4\n",
      "Extracted 50 frames from 3265336.mp4\n",
      "Extracted 50 frames from 3291918.mp4\n",
      "Extracted 50 frames from 3309933.mp4\n",
      "Extracted 50 frames from 3312710.mp4\n",
      "Extracted 50 frames from 3326009.mp4\n",
      "Extracted 50 frames from 3328522.mp4\n",
      "Extracted 50 frames from 3339840.mp4\n",
      "Extracted 50 frames from 3340033.mp4\n",
      "Extracted 50 frames from 3340369.mp4\n",
      "Extracted 50 frames from 3347554.mp4\n",
      "Extracted 50 frames from 3351059.mp4\n",
      "Extracted 50 frames from 3361032.mp4\n",
      "Extracted 50 frames from 3414303.mp4\n",
      "Extracted 50 frames from 3415261.mp4\n",
      "Extracted 50 frames from 3422482.mp4\n"
     ]
    }
   ],
   "source": [
    "# Function to extract 50 clear frames from a video file\n",
    "def extract_frames(video_path, num_frames=50):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames = []\n",
    "    \n",
    "    # Calculate the interval between frames\n",
    "    interval = max(1, total_frames // num_frames)\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        # Set the position of the next frame to read\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * interval)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# Directory with video files\n",
    "video_dir = 'sample/sample/'\n",
    "output_dir = 'extracted_frames/'\n",
    "\n",
    "# Create a directory for extracted frames\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over all video files in the directory\n",
    "for video_file in os.listdir(video_dir):\n",
    "    if video_file.endswith('.mp4'):  # Adjust the extension if needed\n",
    "        video_path = os.path.join(video_dir, video_file)\n",
    "        frames = extract_frames(video_path)\n",
    "        \n",
    "        # Save frames as images\n",
    "        video_output_dir = os.path.join(output_dir, os.path.splitext(video_file)[0])\n",
    "        os.makedirs(video_output_dir, exist_ok=True)\n",
    "        for i, frame in enumerate(frames):\n",
    "            frame_file = os.path.join(video_output_dir, f'frame_{i:04d}.png')\n",
    "            cv2.imwrite(frame_file, frame)\n",
    "        \n",
    "        print(f\"Extracted {len(frames)} frames from {video_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb8af2a",
   "metadata": {},
   "source": [
    "## Part 2: Captioning and Text Recognition from the indivisual frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed08a56b",
   "metadata": {},
   "source": [
    "This code extracts captions and recognized text from image frames of multiple videos and saves the results to a CSV file. It begins by loading a pre-trained image captioning model, a feature extractor, and a tokenizer. It defines three functions: generate_caption to produce captions for frames using the model, recognize_text to extract text from frames using Tesseract OCR, and process_frames to handle frame processing and result collection. It then iterates through video folders, processes the frames, and writes the video ID, generated captions, and recognized text to a CSV file named captioned_frames.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285e5206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd0ca6fd0684b7fb2d242ff925bf858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yesit\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yesit\\.cache\\huggingface\\hub\\models--nlpconnect--vit-gpt2-image-captioning. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4aa49fed94409a99b8ea3f3f530833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/982M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66376633d0584a76851ebc2493afc02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c2859796c84c00a3173d3387333103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/241 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517c77076c34409680b67e71adc47b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8109d650a0ed4d2db5aaad9f013d184d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5deab6bf758c4c1cb7998baa0beb4b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396bb6c757d54e4c8f4f83e8a47320c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved captions for video ID 1471363\n",
      "Processed and saved captions for video ID 1488315\n",
      "Processed and saved captions for video ID 1526213\n",
      "Processed and saved captions for video ID 1548815\n",
      "Processed and saved captions for video ID 1624211\n",
      "Processed and saved captions for video ID 1625396\n",
      "Processed and saved captions for video ID 1641167\n",
      "Processed and saved captions for video ID 1661301\n",
      "Processed and saved captions for video ID 1667694\n",
      "Processed and saved captions for video ID 1671240\n",
      "Processed and saved captions for video ID 1671980\n",
      "Processed and saved captions for video ID 1676138\n",
      "Processed and saved captions for video ID 1678735\n",
      "Processed and saved captions for video ID 1683011\n",
      "Processed and saved captions for video ID 1696112\n",
      "Processed and saved captions for video ID 1702594\n",
      "Processed and saved captions for video ID 1702851\n",
      "Processed and saved captions for video ID 1707220\n",
      "Processed and saved captions for video ID 1708967\n",
      "Processed and saved captions for video ID 1710855\n",
      "Processed and saved captions for video ID 1710993\n",
      "Processed and saved captions for video ID 1713794\n",
      "Processed and saved captions for video ID 1723501\n",
      "Processed and saved captions for video ID 1733728\n",
      "Processed and saved captions for video ID 1739116\n",
      "Processed and saved captions for video ID 1742915\n",
      "Processed and saved captions for video ID 1744482\n",
      "Processed and saved captions for video ID 1747914\n",
      "Processed and saved captions for video ID 1749291\n",
      "Processed and saved captions for video ID 1768584\n",
      "Processed and saved captions for video ID 1776082\n",
      "Processed and saved captions for video ID 1788954\n",
      "Processed and saved captions for video ID 1825984\n",
      "Processed and saved captions for video ID 1913310\n",
      "Processed and saved captions for video ID 1913929\n",
      "Processed and saved captions for video ID 1930720\n",
      "Processed and saved captions for video ID 1934234\n",
      "Processed and saved captions for video ID 1942611\n",
      "Processed and saved captions for video ID 1942695\n",
      "Processed and saved captions for video ID 1951792\n",
      "Processed and saved captions for video ID 1958530\n",
      "Processed and saved captions for video ID 1958838\n",
      "Processed and saved captions for video ID 1959692\n",
      "Processed and saved captions for video ID 1963503\n",
      "Processed and saved captions for video ID 1986629\n",
      "Processed and saved captions for video ID 1991222\n",
      "Processed and saved captions for video ID 2002557\n",
      "Processed and saved captions for video ID 2009582\n",
      "Processed and saved captions for video ID 2032457\n",
      "Processed and saved captions for video ID 2076630\n",
      "Processed and saved captions for video ID 2090919\n",
      "Processed and saved captions for video ID 2142915\n",
      "Processed and saved captions for video ID 2149098\n",
      "Processed and saved captions for video ID 2150923\n",
      "Processed and saved captions for video ID 2160345\n",
      "Processed and saved captions for video ID 2188255\n",
      "Processed and saved captions for video ID 2194673\n",
      "Processed and saved captions for video ID 2205093\n",
      "Processed and saved captions for video ID 2218186\n",
      "Processed and saved captions for video ID 2220795\n",
      "Processed and saved captions for video ID 2238004\n",
      "Processed and saved captions for video ID 2259242\n",
      "Processed and saved captions for video ID 2270982\n",
      "Processed and saved captions for video ID 2293300\n",
      "Processed and saved captions for video ID 2314704\n",
      "Processed and saved captions for video ID 2327598\n",
      "Processed and saved captions for video ID 2327954\n",
      "Processed and saved captions for video ID 2332208\n",
      "Processed and saved captions for video ID 2337786\n",
      "Processed and saved captions for video ID 2352149\n",
      "Processed and saved captions for video ID 2377805\n",
      "Processed and saved captions for video ID 2379465\n",
      "Processed and saved captions for video ID 2381477\n",
      "Processed and saved captions for video ID 2385082\n",
      "Processed and saved captions for video ID 2391348\n",
      "Processed and saved captions for video ID 2407070\n",
      "Processed and saved captions for video ID 2418354\n",
      "Processed and saved captions for video ID 2454123\n",
      "Processed and saved captions for video ID 2466835\n",
      "Processed and saved captions for video ID 2468277\n",
      "Processed and saved captions for video ID 2488408\n",
      "Processed and saved captions for video ID 2505712\n",
      "Processed and saved captions for video ID 2505718\n",
      "Processed and saved captions for video ID 2506189\n",
      "Processed and saved captions for video ID 2507887\n",
      "Processed and saved captions for video ID 2511206\n",
      "Processed and saved captions for video ID 2513974\n",
      "Processed and saved captions for video ID 2520568\n",
      "Processed and saved captions for video ID 2529687\n",
      "Processed and saved captions for video ID 2530396\n",
      "Processed and saved captions for video ID 2540988\n",
      "Processed and saved captions for video ID 2544459\n",
      "Processed and saved captions for video ID 2548638\n",
      "Processed and saved captions for video ID 2558982\n",
      "Processed and saved captions for video ID 2592911\n",
      "Processed and saved captions for video ID 2595709\n",
      "Processed and saved captions for video ID 2597996\n",
      "Processed and saved captions for video ID 2612386\n",
      "Processed and saved captions for video ID 2620437\n",
      "Processed and saved captions for video ID 2650588\n",
      "Processed and saved captions for video ID 2652509\n",
      "Processed and saved captions for video ID 2710205\n",
      "Processed and saved captions for video ID 2714373\n",
      "Processed and saved captions for video ID 2716616\n",
      "Processed and saved captions for video ID 2750416\n",
      "Processed and saved captions for video ID 2755227\n",
      "Processed and saved captions for video ID 2764983\n",
      "Processed and saved captions for video ID 2789795\n",
      "Processed and saved captions for video ID 2807978\n",
      "Processed and saved captions for video ID 2808275\n",
      "Processed and saved captions for video ID 2821872\n",
      "Processed and saved captions for video ID 2853933\n",
      "Processed and saved captions for video ID 2892458\n",
      "Processed and saved captions for video ID 2917037\n",
      "Processed and saved captions for video ID 2953810\n",
      "Processed and saved captions for video ID 2962688\n",
      "Processed and saved captions for video ID 3004458\n",
      "Processed and saved captions for video ID 3019128\n",
      "Processed and saved captions for video ID 3037506\n",
      "Processed and saved captions for video ID 3059869\n",
      "Processed and saved captions for video ID 3066063\n",
      "Processed and saved captions for video ID 3078623\n",
      "Processed and saved captions for video ID 3081313\n",
      "Processed and saved captions for video ID 3111684\n",
      "Processed and saved captions for video ID 3117116\n",
      "Processed and saved captions for video ID 3119347\n",
      "Processed and saved captions for video ID 3124938\n",
      "Processed and saved captions for video ID 3149347\n",
      "Processed and saved captions for video ID 3156128\n",
      "Processed and saved captions for video ID 3168530\n",
      "Processed and saved captions for video ID 3170124\n",
      "Processed and saved captions for video ID 3187482\n",
      "Processed and saved captions for video ID 3209706\n",
      "Processed and saved captions for video ID 3212463\n",
      "Processed and saved captions for video ID 3264190\n",
      "Processed and saved captions for video ID 3265336\n",
      "Processed and saved captions for video ID 3291918\n",
      "Processed and saved captions for video ID 3309933\n",
      "Processed and saved captions for video ID 3312710\n",
      "Processed and saved captions for video ID 3326009\n",
      "Processed and saved captions for video ID 3328522\n",
      "Processed and saved captions for video ID 3339840\n",
      "Processed and saved captions for video ID 3340033\n",
      "Processed and saved captions for video ID 3340369\n",
      "Processed and saved captions for video ID 3347554\n",
      "Processed and saved captions for video ID 3351059\n",
      "Processed and saved captions for video ID 3361032\n",
      "Processed and saved captions for video ID 3414303\n",
      "Processed and saved captions for video ID 3415261\n",
      "Processed and saved captions for video ID 3422482\n"
     ]
    }
   ],
   "source": [
    "# Load the image captioning model\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to generate captions for a frame\n",
    "def generate_caption(frame):\n",
    "    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    pixel_values = inputs.pixel_values.to(device)\n",
    "\n",
    "    output_ids = model.generate(pixel_values, max_new_tokens=50)\n",
    "    caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "# Function to recognize text in a frame using Tesseract OCR\n",
    "def recognize_text(frame):\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    text = pytesseract.image_to_string(rgb_frame)\n",
    "    return text\n",
    "\n",
    "# Function to process frames and generate captions and recognized text\n",
    "def process_frames(frames_path):\n",
    "    results = []\n",
    "\n",
    "    for frame_file in sorted(os.listdir(frames_path)):\n",
    "        if frame_file.endswith('.png'):  # Assuming frames are saved as PNG\n",
    "            frame_path = os.path.join(frames_path, frame_file)\n",
    "            frame = cv2.imread(frame_path)\n",
    "            caption = generate_caption(frame)\n",
    "            recognized_text = recognize_text(frame)\n",
    "            results.append({\n",
    "                \"caption\": caption,\n",
    "                \"recognized_text\": recognized_text\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Function to save the results to a CSV file\n",
    "def save_results_to_csv(results, video_id, csv_writer):\n",
    "    for result in results:\n",
    "        csv_writer.writerow([video_id, result['caption'], result['recognized_text']])\n",
    "\n",
    "# Directory with extracted frames\n",
    "extracted_frames_dir = 'extracted_frames'\n",
    "output_csv = 'captioned_frames.csv'\n",
    "\n",
    "# Create the CSV file and write headers\n",
    "with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerow(['video_id', 'caption', 'recognized_text'])\n",
    "\n",
    "    # Iterate over all video folders in the directory\n",
    "    for video_id in os.listdir(extracted_frames_dir):\n",
    "        video_frames_path = os.path.join(extracted_frames_dir, video_id)\n",
    "        if os.path.isdir(video_frames_path):\n",
    "            results = process_frames(video_frames_path)\n",
    "            \n",
    "            # Save the results to the CSV file\n",
    "            save_results_to_csv(results, video_id, csv_writer)\n",
    "            \n",
    "            print(f\"Processed and saved captions for video ID {video_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9bd2b5",
   "metadata": {},
   "source": [
    "## Part 3: Summarizing Individual Captions Generated and Texts from Frames and Joining Them with the Video Description and Audio Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6925c4",
   "metadata": {},
   "source": [
    "This code generates summaries for combined captions and recognized text from video frames and saves the results to a new CSV file. It starts by loading a pre-trained BART model and tokenizer for text summarization. The generate_summary function processes text inputs to create concise summaries. The script reads an existing CSV file (captioned_frames.csv) containing captions and recognized text, groups the data by video_id, and combines the text for each video. It then generates two summaries per video: one for the combined captions and another for the combined recognized text. Finally, it saves the video IDs along with their summaries into a new CSV file named new.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a59815c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed for video: 0\n",
      "Processed for video: 1\n",
      "Processed for video: 2\n",
      "Processed for video: 3\n",
      "Processed for video: 4\n",
      "Processed for video: 5\n",
      "Processed for video: 6\n",
      "Processed for video: 7\n",
      "Processed for video: 8\n",
      "Processed for video: 9\n",
      "Processed for video: 10\n",
      "Processed for video: 11\n",
      "Processed for video: 12\n",
      "Processed for video: 13\n",
      "Processed for video: 14\n",
      "Processed for video: 15\n",
      "Processed for video: 16\n",
      "Processed for video: 17\n",
      "Processed for video: 18\n",
      "Processed for video: 19\n",
      "Processed for video: 20\n",
      "Processed for video: 21\n",
      "Processed for video: 22\n",
      "Processed for video: 23\n",
      "Processed for video: 24\n",
      "Processed for video: 25\n",
      "Processed for video: 26\n",
      "Processed for video: 27\n",
      "Processed for video: 28\n",
      "Processed for video: 29\n",
      "Processed for video: 30\n",
      "Processed for video: 31\n",
      "Processed for video: 32\n",
      "Processed for video: 33\n",
      "Processed for video: 34\n",
      "Processed for video: 35\n",
      "Processed for video: 36\n",
      "Processed for video: 37\n",
      "Processed for video: 38\n",
      "Processed for video: 39\n",
      "Processed for video: 40\n",
      "Processed for video: 41\n",
      "Processed for video: 42\n",
      "Processed for video: 43\n",
      "Processed for video: 44\n",
      "Processed for video: 45\n",
      "Processed for video: 46\n",
      "Processed for video: 47\n",
      "Processed for video: 48\n",
      "Processed for video: 49\n",
      "Processed for video: 50\n",
      "Processed for video: 51\n",
      "Processed for video: 52\n",
      "Processed for video: 53\n",
      "Processed for video: 54\n",
      "Processed for video: 55\n",
      "Processed for video: 56\n",
      "Processed for video: 57\n",
      "Processed for video: 58\n",
      "Processed for video: 59\n",
      "Processed for video: 60\n",
      "Processed for video: 61\n",
      "Processed for video: 62\n",
      "Processed for video: 63\n",
      "Processed for video: 64\n",
      "Processed for video: 65\n",
      "Processed for video: 66\n",
      "Processed for video: 67\n",
      "Processed for video: 68\n",
      "Processed for video: 69\n",
      "Processed for video: 70\n",
      "Processed for video: 71\n",
      "Processed for video: 72\n",
      "Processed for video: 73\n",
      "Processed for video: 74\n",
      "Processed for video: 75\n",
      "Processed for video: 76\n",
      "Processed for video: 77\n",
      "Processed for video: 78\n",
      "Processed for video: 79\n",
      "Processed for video: 80\n",
      "Processed for video: 81\n",
      "Processed for video: 82\n",
      "Processed for video: 83\n",
      "Processed for video: 84\n",
      "Processed for video: 85\n",
      "Processed for video: 86\n",
      "Processed for video: 87\n",
      "Processed for video: 88\n",
      "Processed for video: 89\n",
      "Processed for video: 90\n",
      "Processed for video: 91\n",
      "Processed for video: 92\n",
      "Processed for video: 93\n",
      "Processed for video: 94\n",
      "Processed for video: 95\n",
      "Processed for video: 96\n",
      "Processed for video: 97\n",
      "Processed for video: 98\n",
      "Processed for video: 99\n",
      "Processed for video: 100\n",
      "Processed for video: 101\n",
      "Processed for video: 102\n",
      "Processed for video: 103\n",
      "Processed for video: 104\n",
      "Processed for video: 105\n",
      "Processed for video: 106\n",
      "Processed for video: 107\n",
      "Processed for video: 108\n",
      "Processed for video: 109\n",
      "Processed for video: 110\n",
      "Processed for video: 111\n",
      "Processed for video: 112\n",
      "Processed for video: 113\n",
      "Processed for video: 114\n",
      "Processed for video: 115\n",
      "Processed for video: 116\n",
      "Processed for video: 117\n",
      "Processed for video: 118\n",
      "Processed for video: 119\n",
      "Processed for video: 120\n",
      "Processed for video: 121\n",
      "Processed for video: 122\n",
      "Processed for video: 123\n",
      "Processed for video: 124\n",
      "Processed for video: 125\n",
      "Processed for video: 126\n",
      "Processed for video: 127\n",
      "Processed for video: 128\n",
      "Processed for video: 129\n",
      "Processed for video: 130\n",
      "Processed for video: 131\n",
      "Processed for video: 132\n",
      "Processed for video: 133\n",
      "Processed for video: 134\n",
      "Processed for video: 135\n",
      "Processed for video: 136\n",
      "Processed for video: 137\n",
      "Processed for video: 138\n",
      "Processed for video: 139\n",
      "Processed for video: 140\n",
      "Processed for video: 141\n",
      "Processed for video: 142\n",
      "Processed for video: 143\n",
      "Processed for video: 144\n",
      "Processed for video: 145\n",
      "Processed for video: 146\n",
      "Processed for video: 147\n",
      "Processed for video: 148\n",
      "Processed for video: 149\n",
      "Summaries have been saved to new.csv\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BART model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Function to generate summary\n",
    "def generate_summary(text):\n",
    "    # Check if the text is empty\n",
    "    if not text.strip():\n",
    "        return \"No text available for summarization.\"\n",
    "    \n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# input CSV file and the output CSV file\n",
    "input_csv_path = \"captioned_frames.csv\"\n",
    "output_csv_path = \"new.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Group the DataFrame by 'video_id' and combine 'caption' and 'recognized_text' for each group\n",
    "grouped = df.groupby('video_id').agg({\n",
    "    'caption': lambda x: ' '.join(x),\n",
    "    'recognized_text': lambda x: ' '.join(x.dropna().fillna(''))  # Drop NaNs and replace empty entries with ''\n",
    "}).reset_index()\n",
    "\n",
    "# Generate summaries for each combined text\n",
    "summaries_caption = []\n",
    "summaries_text_recognition = []\n",
    "video_ids = []\n",
    "i=0\n",
    "# Iterate over each row in the grouped DataFrame\n",
    "for index, row in grouped.iterrows():\n",
    "    video_id = row['video_id']\n",
    "    combined_caption = row['caption']\n",
    "    combined_text_recognition = row['recognized_text']\n",
    "    \n",
    "    # Generate summaries\n",
    "    summary1 = generate_summary(combined_caption)\n",
    "    summary2 = generate_summary(combined_text_recognition)\n",
    "    \n",
    "    # Append results to lists\n",
    "    video_ids.append(video_id)\n",
    "    summaries_caption.append(summary1)\n",
    "    summaries_text_recognition.append(summary2)\n",
    "    print('Processed for video:',i)\n",
    "    i=i+1\n",
    "\n",
    "# Create a new DataFrame with VideoID and Summary\n",
    "summary_df = pd.DataFrame({\n",
    "    'VideoID': video_ids,\n",
    "    'Caption Summary': summaries_caption,\n",
    "    'Text Summary': summaries_text_recognition\n",
    "})\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "summary_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Summaries have been saved to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190042a",
   "metadata": {},
   "source": [
    "### Part 3-A: Join the Columns from Sample.csv to the Summarized Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e8a0847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries have been saved to new.csv\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Sample.csv')\n",
    "# Merge with the description and speech DataFrames\n",
    "summary_df = summary_df.merge(data[['creative_data_id', 'creative_data_description']], left_on='VideoID', right_on='creative_data_id', how='left')\n",
    "summary_df = summary_df.merge(data[['creative_data_id', 'speech']], left_on='VideoID', right_on='creative_data_id', how='left')\n",
    "\n",
    "# Drop the redundant 'video_id' columns from the merged DataFrames\n",
    "summary_df.drop(columns=['creative_data_id_x', 'creative_data_id_y'], inplace=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "summary_df.rename(columns={'description': 'Description', 'speech': 'Speech'}, inplace=True)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "summary_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Summaries have been saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d48f3c0",
   "metadata": {},
   "source": [
    "## Part 4: Text Classification, Question Answering and converting Confidence score to Yes/No format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9132367",
   "metadata": {},
   "source": [
    "This code classifies text data from a CSV file using a zero-shot classification model and saves the results to two separate CSV files. It first reads a CSV file containing video IDs and various text summaries. For each video, it prepares a combined text from the video description, speech, caption summary, and text summary, and then applies a zero-shot classification model to answer a set of predefined questions about the content. The code initializes a BART-based classification pipeline, processes each video’s text to generate scores and labels for each question, and finally saves the classification results (scores and labels) to results_scores.csv and results_labeled.csv, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba82074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a text classification model\n",
    "classifier = pipeline('text-classification', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "# Define a function to classify text\n",
    "def classify_text(text, question):\n",
    "    prompt = f\"{question}\\n{text}\"\n",
    "    result = classifier(prompt)\n",
    "    return result[0]['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30cfe883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed for  1471363\n",
      "Processed for  1488315\n",
      "Processed for  1526213\n",
      "Processed for  1548815\n",
      "Processed for  1624211\n",
      "Processed for  1625396\n",
      "Processed for  1641167\n",
      "Processed for  1661301\n",
      "Processed for  1667694\n",
      "Processed for  1671240\n",
      "Processed for  1671980\n",
      "Processed for  1676138\n",
      "Processed for  1678735\n",
      "Processed for  1683011\n",
      "Processed for  1696112\n",
      "Processed for  1702594\n",
      "Processed for  1702851\n",
      "Processed for  1707220\n",
      "Processed for  1708967\n",
      "Processed for  1710855\n",
      "Processed for  1710993\n",
      "Processed for  1713794\n",
      "Processed for  1723501\n",
      "Processed for  1733728\n",
      "Processed for  1739116\n",
      "Processed for  1742915\n",
      "Processed for  1744482\n",
      "Processed for  1747914\n",
      "Processed for  1749291\n",
      "Processed for  1768584\n",
      "Processed for  1776082\n",
      "Processed for  1788954\n",
      "Processed for  1825984\n",
      "Processed for  1913310\n",
      "Processed for  1913929\n",
      "Processed for  1930720\n",
      "Processed for  1934234\n",
      "Processed for  1942611\n",
      "Processed for  1942695\n",
      "Processed for  1951792\n",
      "Processed for  1958530\n",
      "Processed for  1958838\n",
      "Processed for  1959692\n",
      "Processed for  1963503\n",
      "Processed for  1986629\n",
      "Processed for  1991222\n",
      "Processed for  2002557\n",
      "Processed for  2009582\n",
      "Processed for  2032457\n",
      "Processed for  2076630\n",
      "Processed for  2090919\n",
      "Processed for  2142915\n",
      "Processed for  2149098\n",
      "Processed for  2150923\n",
      "Processed for  2160345\n",
      "Processed for  2188255\n",
      "Processed for  2194673\n",
      "Processed for  2205093\n",
      "Processed for  2218186\n",
      "Processed for  2220795\n",
      "Processed for  2238004\n",
      "Processed for  2259242\n",
      "Processed for  2270982\n",
      "Processed for  2293300\n",
      "Processed for  2314704\n",
      "Processed for  2327598\n",
      "Processed for  2327954\n",
      "Processed for  2332208\n",
      "Processed for  2337786\n",
      "Processed for  2352149\n",
      "Processed for  2377805\n",
      "Processed for  2379465\n",
      "Processed for  2381477\n",
      "Processed for  2385082\n",
      "Processed for  2391348\n",
      "Processed for  2407070\n",
      "Processed for  2418354\n",
      "Processed for  2454123\n",
      "Processed for  2466835\n",
      "Processed for  2468277\n",
      "Processed for  2488408\n",
      "Processed for  2505712\n",
      "Processed for  2505718\n",
      "Processed for  2506189\n",
      "Processed for  2507887\n",
      "Processed for  2511206\n",
      "Processed for  2513974\n",
      "Processed for  2520568\n",
      "Processed for  2529687\n",
      "Processed for  2530396\n",
      "Processed for  2540988\n",
      "Processed for  2544459\n",
      "Processed for  2548638\n",
      "Processed for  2558982\n",
      "Processed for  2592911\n",
      "Processed for  2595709\n",
      "Processed for  2597996\n",
      "Processed for  2612386\n",
      "Processed for  2620437\n",
      "Processed for  2650588\n",
      "Processed for  2652509\n",
      "Processed for  2710205\n",
      "Processed for  2714373\n",
      "Processed for  2716616\n",
      "Processed for  2750416\n",
      "Processed for  2755227\n",
      "Processed for  2764983\n",
      "Processed for  2789795\n",
      "Processed for  2807978\n",
      "Processed for  2808275\n",
      "Processed for  2821872\n",
      "Processed for  2853933\n",
      "Processed for  2892458\n",
      "Processed for  2917037\n",
      "Processed for  2953810\n",
      "Processed for  2962688\n",
      "Processed for  3004458\n",
      "Processed for  3019128\n",
      "Processed for  3037506\n",
      "Processed for  3059869\n",
      "Processed for  3066063\n",
      "Processed for  3078623\n",
      "Processed for  3081313\n",
      "Processed for  3111684\n",
      "Processed for  3117116\n",
      "Processed for  3119347\n",
      "Processed for  3124938\n",
      "Processed for  3149347\n",
      "Processed for  3156128\n",
      "Processed for  3168530\n",
      "Processed for  3170124\n",
      "Processed for  3187482\n",
      "Processed for  3209706\n",
      "Processed for  3212463\n",
      "Processed for  3264190\n",
      "Processed for  3265336\n",
      "Processed for  3291918\n",
      "Processed for  3309933\n",
      "Processed for  3312710\n",
      "Processed for  3326009\n",
      "Processed for  3328522\n",
      "Processed for  3339840\n",
      "Processed for  3340033\n",
      "Processed for  3340369\n",
      "Processed for  3347554\n",
      "Processed for  3351059\n",
      "Processed for  3361032\n",
      "Processed for  3414303\n",
      "Processed for  3415261\n",
      "Processed for  3422482\n"
     ]
    }
   ],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('new.csv')\n",
    "\n",
    "# Prepare text for classification\n",
    "data_for_classification = []\n",
    "for index, row in df.iterrows():\n",
    "    video_id = row['VideoID']\n",
    "    description = row['creative_data_description']\n",
    "    speech = row['Speech']\n",
    "    caption_summary = row['Caption Summary']\n",
    "    text_summary = row['Text Summary']\n",
    "\n",
    "    text = f\"Video Description: {description}\\nSpeech: {speech}\\nCaption Summary: {caption_summary}\\nText Summary: {text_summary}\"\n",
    "    data_for_classification.append({'video_id': video_id, 'text': text})\n",
    "\n",
    "# questions\n",
    "questions = {\n",
    "    'call_to_online': \"Does the text contain a call to go online (e.g., shop online, visit the Web)?\",\n",
    "    'online_contact_info': \"Does the text provide online contact information (e.g., URL, website)?\",\n",
    "    'visual_or_verbal_call_to_purchase': \"Does the text include a visual or verbal call to purchase (e.g., buy now, order now)?\",\n",
    "    'urgency_to_act': \"Does the text portray a sense of urgency to act (e.g., buy before sales end, order before it ends)?\",\n",
    "    'incentive_to_buy': \"Does the text provide an incentive to buy (e.g., a discount, a coupon, a sale, or 'limited time offer')?\",\n",
    "    'offline_contact_info': \"Does the text provide offline contact information (e.g., phone, mail, store location)?\",\n",
    "    'mention_of_something_free': \"Does the text mention something free?\",\n",
    "    'specific_product_or_service': \"Does the text mention at least one specific product or service (e.g., model, type, item)?\",\n",
    "    'mention_of_price': \"Does the text mention a price?\",\n",
    "    'brand_shown_multiple_times': \"Does the text indicate that the brand (logo, brand name) or trademark is shown multiple times?\",\n",
    "    'brand_shown_once_at_end': \"Does the text indicate that the brand or trademark is shown exactly once at the end of the ad?\",\n",
    "    'emotional_intent': \"Is the ad intended to affect the viewer emotionally, either with positive or negative emotions, based on the text?\",\n",
    "    'positive_feeling_about_brand': \"Does the text give a positive feeling about the brand?\",\n",
    "    'story_arc': \"Does the ad have a story arc, with a beginning and an end, based on the text?\",\n",
    "    'reversal_of_fortune': \"Does the ad have a reversal of fortune, where something changes for the better or worse?\",\n",
    "    'relatable_characters': \"Does the ad have relatable characters based on the text?\",\n",
    "    'creative_or_clever': \"Is the ad creative or clever based on the text?\",\n",
    "    'funny_intent': \"Is the ad intended to be funny based on the text?\",\n",
    "    'sensory_stimulation': \"Does the ad provide sensory stimulation (e.g., cool visuals, arousing music, mouth-watering) based on the text?\",\n",
    "    'visually_pleasing': \"Is the ad visually pleasing based on the text?\",\n",
    "    'cute_elements': \"Does the ad have cute elements like animals, babies, animated characters, etc., based on the text?\"\n",
    "}\n",
    "\n",
    "# Initialize classification pipeline\n",
    "classifier = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')\n",
    "\n",
    "# Initialize DataFrames for scores and labels\n",
    "scores_df = pd.DataFrame()\n",
    "labels_df = pd.DataFrame()\n",
    "\n",
    "for data in data_for_classification:\n",
    "    video_id = data['video_id']\n",
    "    text = data['text']\n",
    "\n",
    "    scores = {'video_id': video_id}\n",
    "    labels = {'video_id': video_id}\n",
    "    for question_key, question_text in questions.items():\n",
    "        result = classifier(text, [question_text])\n",
    "        # Extract the score\n",
    "        score = result['scores'][0]\n",
    "        scores[question_key] = score\n",
    "        # Label score as 'Yes' or 'No'\n",
    "        label = 'Yes' if score > 0.72 else 'No'\n",
    "        labels[question_key] = label\n",
    "    \n",
    "    scores_df = scores_df.append(scores, ignore_index=True)\n",
    "    labels_df = labels_df.append(labels, ignore_index=True)\n",
    "    print('Processed for ', data['video_id'])\n",
    "\n",
    "# Save scores and labels to separate CSV files\n",
    "scores_df.to_csv('results_scores.csv', index=False)\n",
    "labels_df.to_csv('results_labeled.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051953b5",
   "metadata": {},
   "source": [
    "## Part 5: Processing the Ground Truth Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f147025a",
   "metadata": {},
   "source": [
    "### Part 5-A: Removing Unecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bdaa178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['creative_data_id',\n",
      "       'Is there a call to go online (e.g., shop online, visit the Web)? ',\n",
      "       'Is there online contact information provided (e.g., URL, website)? ',\n",
      "       'Is there a visual or verbal call to purchase (e.g., buy now, order now)?',\n",
      "       'Does the ad portray a sense of urgency to act (e.g., buy before sales ends, order before ends)? ',\n",
      "       'Is there an incentive to buy (e.g., a discount, a coupon, a sale or \"limited time offer\")? ',\n",
      "       'Is there offline contact information provided (e.g., phone, mail, store location)?',\n",
      "       'Is there mention of something free? ',\n",
      "       'Does the ad mention at least one specific product or service (e.g., model, type, item)? ',\n",
      "       'Is there any verbal or visual mention of the price?',\n",
      "       'Does the ad show the brand (logo, brand name) or trademark (something that most people know is the brand) multiple times?\\n\\nFor example, Nike ads often have the \"swoosh\" logo prominently displayed on shoes and apparel worn by celebrity athletes. The \"Just Do It\" slogan is another Nike trademark frequently included.',\n",
      "       'Does the ad show the brand or trademark exactly once at the end of the ad?',\n",
      "       'Is the ad intended to affect the viewer emotionally, either with positive emotion (fun, joy), negative emotion (sad, anxious) or another type of emotion? (Note: You may not personally agree, but assess if that was the intention.)',\n",
      "       'Does the ad give you a positive feeling about the brand? ',\n",
      "       'Does the ad have a story arc, with a beginning and an end? ',\n",
      "       'Does the ad have a reversal of fortune, where something changes for the better, or changes for the worse?',\n",
      "       'Does the ad have relatable characters? ', 'Is the ad creative/clever?',\n",
      "       'Is the ad intended to be funny? (Note: You may not personally agree, but assess if that was the intention.) ',\n",
      "       'Does this ad provide sensory stimulation (e.g., cool visuals, arousing music, mouth-watering)? ',\n",
      "       'Is the ad visually pleasing?',\n",
      "       'Does the ad have cute elements like animals, babies, animated, characters, etc?'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "input_excel_path = \"ground_truth.xlsx\"  # Update this with the path to your Excel file\n",
    "df = pd.read_excel(input_excel_path)\n",
    "# Drop specific columns\n",
    "columns_to_drop = ['Timestamp',\n",
    "    'If \"yes\" to the above, which of the following emotions is closest to the emotion that the ad was intending the viewer to feel? (Select all that apply.)', \n",
    "                   'If yes to the above, did the ad successfully affect you emotionally, as intended?',\n",
    "                   'If yes to the above, was the ad successfully funny, as intended?',\n",
    "                   'Was there a famous person in this ad? ',\n",
    "       'If yes to the above, write the name of the famous person, if known.',\n",
    "       'What happened in this ad? (Answer in 2-3 sentences each)',\n",
    "       'What was/were the company\\'s goal(s) with this ad? Choose (potentially multiple) from:',\n",
    "       'How successful was the ad in achieving its goal(s)?',\n",
    "       'How much did you like the ad? (1. Strongly dislike, 2. Dislike, 3. Neither Like or Dislike, 4. Like, 5. Strongly Like)',\n",
    "       'What was the slogan presented in the ad, if any?',\n",
    "       'After addressing the specific survey items, write a general description of the ad. You can use answers to the questions above to formulate your answer. Your description should include:\\nBrand and Product Identification: \\nSpecify the brand and whether a product is being advertised. (1 sentence)\\nVisual Elements: Describe what is seen on the screen, including setting, characters, and any text or graphics. (max 2 sentences)\\nAuditory Elements: Note what is heard, such as dialogue, voice-over, music, or sound effects. (max 2 sentences)\\n',\n",
    "       'Any additional feedback or things we should be aware of? ',\n",
    "       'Please enter the video identifier one more time (e.g. 123456789.mp4)'\n",
    "                  ]  # Update this with the columns you want to drop\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faedea8",
   "metadata": {},
   "source": [
    "### Part 5-B: Handeling values and Renaming of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf96e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of remaining columns from the 2nd column onwards\n",
    "remaining_columns = df.columns[1:]\n",
    "\n",
    "# Create new column names\n",
    "new_column_names = [f'question_{i+1}' for i in range(len(remaining_columns))]\n",
    "\n",
    "# Rename the remaining columns\n",
    "df.rename(columns=dict(zip(remaining_columns, new_column_names)), inplace=True)\n",
    "\n",
    "# replcing values like 'Yes,Both', 'Yes, Visual' to simply 'Yes' and 'No'\n",
    "def replace_values(cell):\n",
    "    if cell.lower().startswith(\"yes\"):\n",
    "        return \"Yes\"\n",
    "    elif cell.lower() == \"no\":\n",
    "        return \"No\"\n",
    "    return cell\n",
    "\n",
    "# Apply the function to the relevant columns\n",
    "for col in new_column_names:\n",
    "    df[col] = df[col].apply(replace_values)\n",
    "\n",
    "# Save the updated CSV\n",
    "df.to_csv('updated_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09dffc4",
   "metadata": {},
   "source": [
    "### Part 5-C: Assigning Values(Yes/No) based on majority vote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61ea3e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     creative_data_id question_1 question_2 question_3 question_4 question_5  \\\n",
      "0             1471363         No        Yes         No         No         No   \n",
      "1             1488315         No         No         No         No         No   \n",
      "2             1526213         No         No         No         No        Yes   \n",
      "3             1548815         No         No         No         No         No   \n",
      "4             1624211         No        Yes         No         No         No   \n",
      "..                ...        ...        ...        ...        ...        ...   \n",
      "145           3351059         No         No        Yes         No        Yes   \n",
      "146           3361032         No         No         No         No         No   \n",
      "147           3414303         No         No         No         No         No   \n",
      "148           3415261         No        Yes         No         No         No   \n",
      "149           3422482         No         No        Yes        Yes        Yes   \n",
      "\n",
      "    question_6 question_7 question_8 question_9  ... question_12 question_13  \\\n",
      "0           No         No        Yes         No  ...         Yes         Yes   \n",
      "1           No         No        Yes         No  ...         Yes         Yes   \n",
      "2          Yes         No        Yes        Yes  ...          No         Yes   \n",
      "3           No         No        Yes         No  ...         Yes         Yes   \n",
      "4           No         No        Yes         No  ...         Yes         Yes   \n",
      "..         ...        ...        ...        ...  ...         ...         ...   \n",
      "145         No         No        Yes         No  ...          No         Yes   \n",
      "146         No         No        Yes         No  ...         Yes         Yes   \n",
      "147         No         No         No         No  ...         Yes         Yes   \n",
      "148         No         No        Yes         No  ...         Yes         Yes   \n",
      "149         No         No        Yes         No  ...         Yes         Yes   \n",
      "\n",
      "    question_14 question_15 question_16 question_17 question_18 question_19  \\\n",
      "0           Yes          No         Yes          No          No         Yes   \n",
      "1           Yes          No          No         Yes          No         Yes   \n",
      "2            No          No          No         Yes          No         Yes   \n",
      "3           Yes          No         Yes         Yes         Yes          No   \n",
      "4            No          No         Yes         Yes          No         Yes   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "145          No          No         Yes         Yes          No         Yes   \n",
      "146         Yes          No         Yes         Yes          No          No   \n",
      "147         Yes          No         Yes          No         Yes          No   \n",
      "148          No          No          No         Yes          No         Yes   \n",
      "149          No          No         Yes         Yes          No         Yes   \n",
      "\n",
      "    question_20 question_21  \n",
      "0           Yes          No  \n",
      "1            No          No  \n",
      "2           Yes          No  \n",
      "3           Yes         Yes  \n",
      "4           Yes          No  \n",
      "..          ...         ...  \n",
      "145          No          No  \n",
      "146         Yes         Yes  \n",
      "147         Yes          No  \n",
      "148         Yes          No  \n",
      "149         Yes          No  \n",
      "\n",
      "[150 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "for col in new_column_names:\n",
    "    df[col] = df[col].apply(replace_values)\n",
    "\n",
    "# Function to determine ground truth for each video\n",
    "def determine_ground_truth(group):\n",
    "    ground_truth = {}\n",
    "    for col in new_column_names:\n",
    "        votes = group[col].tolist()\n",
    "        vote_count = Counter(votes)\n",
    "        if vote_count['Yes'] > vote_count['No']:\n",
    "            ground_truth[col] = 'Yes'\n",
    "        elif vote_count['No'] > vote_count['Yes']:\n",
    "            ground_truth[col] = 'No'\n",
    "        else:\n",
    "            ground_truth[col] = 'Yes'  # Tie resolved in favor of 'Yes'\n",
    "    return pd.Series(ground_truth)\n",
    "\n",
    "# Group by 'creative_data_id' and apply the ground truth determination\n",
    "ground_truth_df = df.groupby('creative_data_id').apply(determine_ground_truth).reset_index()\n",
    "\n",
    "# Save the updated CSV\n",
    "ground_truth_df.to_csv('ground_truth_file.csv', index=False)\n",
    "\n",
    "print(ground_truth_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a1651c",
   "metadata": {},
   "source": [
    "## Part 6 : Evaluation of Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69c335",
   "metadata": {},
   "source": [
    "### Part 6-A: Overall Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e0548",
   "metadata": {},
   "source": [
    "Evaluates the performance of a zero-shot classification model by comparing its predicted answers against ground truth values. It starts by loading predicted and ground truth CSV files, renaming columns for consistency, and ensuring that the video IDs and columns match between the two datasets. The script then compares predictions and true values for each question, calculating metrics such as precision, recall, F1 score, accuracy, specificity, NPV (negative predictive value), FPR (false positive rate), FNR (false negative rate), and MCC (Matthews correlation coefficient). It also computes the percentage of agreements between predictions and ground truth. Finally, it prints out these evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fff22db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Precision: 0.59\n",
      "Overall Recall: 0.83\n",
      "Overall F1 Score: 0.69\n",
      "Overall Accuracy: 0.64\n",
      "Overall Specificity: 0.46\n",
      "Overall NPV: 0.75\n",
      "Overall FPR: 0.54\n",
      "Overall FNR: 0.17\n",
      "Overall MCC: 0.32\n",
      "Agreement Percentage: 63.90%\n"
     ]
    }
   ],
   "source": [
    "# Load the predicted answers and ground truth values\n",
    "predicted_df = pd.read_csv('results_labeled.csv')\n",
    "ground_truth_df = pd.read_csv('ground_truth_file.csv')\n",
    "\n",
    "# Rename the ID column in ground_truth_df to match predicted_df\n",
    "ground_truth_df.rename(columns={'creative_data_id': 'video_id'}, inplace=True)\n",
    "\n",
    "# Get the list of remaining columns from the 2nd column onwards\n",
    "remaining_columns = predicted_df.columns[1:]\n",
    "\n",
    "# Create new column names for the predicted DataFrame\n",
    "new_column_names = [f'question_{i+1}' for i in range(len(remaining_columns))]\n",
    "\n",
    "# Rename the remaining columns in the predicted DataFrame\n",
    "predicted_df.rename(columns=dict(zip(remaining_columns, new_column_names)), inplace=True)\n",
    "\n",
    "# Rename the corresponding columns in the ground truth DataFrame\n",
    "ground_truth_df.rename(columns=dict(zip(remaining_columns, new_column_names)), inplace=True)\n",
    "assert (predicted_df.columns == ground_truth_df.columns).all(), \"Columns do not match\"\n",
    "assert (predicted_df['video_id'] == ground_truth_df['video_id']).all(), \"Video IDs do not match\"\n",
    "\n",
    "# Extract the question columns, skipping the 'video_id' column\n",
    "questions = predicted_df.columns[1:]  # All columns except 'video_id'\n",
    "\n",
    "# Initialize lists to store all the predictions and true values\n",
    "all_y_pred = []\n",
    "all_y_true = []\n",
    "all_agreements = 0  # Initialize a counter for agreements\n",
    "\n",
    "# Iterate over each question column\n",
    "for question in questions:\n",
    "    # Extract the predicted and true values for the current question\n",
    "    y_pred = predicted_df[question].map({'Yes': 1, 'No': 0}).values\n",
    "    y_true = ground_truth_df[question].map({'Yes': 1, 'No': 0}).values\n",
    "    \n",
    "    # Calculate the number of agreements for this question\n",
    "    agreements = (y_pred == y_true).sum()\n",
    "    all_agreements += agreements\n",
    "    \n",
    "    # Append the values to the overall lists\n",
    "    all_y_pred.extend(y_pred)\n",
    "    all_y_true.extend(y_true)\n",
    "\n",
    "# Calculate the overall metrics\n",
    "overall_precision = precision_score(all_y_true, all_y_pred)\n",
    "overall_recall = recall_score(all_y_true, all_y_pred)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred)\n",
    "overall_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "conf_matrix = confusion_matrix(all_y_true, all_y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "overall_specificity = tn / (tn + fp)\n",
    "overall_npv = tn / (tn + fn)\n",
    "overall_fpr = fp / (fp + tn)\n",
    "overall_fnr = fn / (fn + tp)\n",
    "overall_mcc = matthews_corrcoef(all_y_true, all_y_pred)\n",
    "\n",
    "# Calculate the agreement percentage\n",
    "total_comparisons = len(all_y_pred)  # Total number of comparisons (predictions)\n",
    "agreement_percentage = (all_agreements / total_comparisons) * 100  # Convert to percentage\n",
    "\n",
    "# Print the overall scores\n",
    "print(f\"Overall Precision: {overall_precision:.2f}\")\n",
    "print(f\"Overall Recall: {overall_recall:.2f}\")\n",
    "print(f\"Overall F1 Score: {overall_f1:.2f}\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.2f}\")\n",
    "print(f\"Overall Specificity: {overall_specificity:.2f}\")\n",
    "print(f\"Overall NPV: {overall_npv:.2f}\")\n",
    "print(f\"Overall FPR: {overall_fpr:.2f}\")\n",
    "print(f\"Overall FNR: {overall_fnr:.2f}\")\n",
    "print(f\"Overall MCC: {overall_mcc:.2f}\")\n",
    "print(f\"Agreement Percentage: {agreement_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736b40a8",
   "metadata": {},
   "source": [
    "### Part 6-B: Questionwise Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23907f73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Question 1: Is there a call to go online (e.g., shop online, visit the Web)?\n",
      "  Precision: 0.43\n",
      "  Recall: 0.60\n",
      "  F1 Score: 0.50\n",
      "  Agreement Percentage: 65.33%\n",
      "\n",
      "Metrics for Question 2: Is online contact information provided (e.g., URL, website)?\n",
      "  Precision: 0.55\n",
      "  Recall: 0.44\n",
      "  F1 Score: 0.49\n",
      "  Agreement Percentage: 58.00%\n",
      "\n",
      "Metrics for Question 3: Is there a visual or verbal call to purchase (e.g., buy now, order now)?\n",
      "  Precision: 0.40\n",
      "  Recall: 0.93\n",
      "  F1 Score: 0.56\n",
      "  Agreement Percentage: 46.00%\n",
      "\n",
      "Metrics for Question 4: Does the ad portray a sense of urgency to act (e.g., buy before sales end, order before it ends)?\n",
      "  Precision: 0.39\n",
      "  Recall: 0.55\n",
      "  F1 Score: 0.45\n",
      "  Agreement Percentage: 64.67%\n",
      "\n",
      "Metrics for Question 5: Is there an incentive to buy (e.g., a discount, a coupon, a sale, or 'limited time offer')?\n",
      "  Precision: 0.57\n",
      "  Recall: 0.92\n",
      "  F1 Score: 0.71\n",
      "  Agreement Percentage: 66.00%\n",
      "\n",
      "Metrics for Question 6: Is offline contact information provided (e.g., phone, mail, store location)?\n",
      "  Precision: 0.20\n",
      "  Recall: 0.48\n",
      "  F1 Score: 0.28\n",
      "  Agreement Percentage: 56.00%\n",
      "\n",
      "Metrics for Question 7: Is there mention of something free?\n",
      "  Precision: 0.17\n",
      "  Recall: 1.00\n",
      "  F1 Score: 0.29\n",
      "  Agreement Percentage: 60.00%\n",
      "\n",
      "Metrics for Question 8: Does the ad mention at least one specific product or service (e.g., model, type, item)?\n",
      "  Precision: 0.86\n",
      "  Recall: 0.98\n",
      "  F1 Score: 0.91\n",
      "  Agreement Percentage: 84.00%\n",
      "\n",
      "Metrics for Question 9: Is there any verbal or visual mention of the price?\n",
      "  Precision: 0.76\n",
      "  Recall: 0.45\n",
      "  F1 Score: 0.57\n",
      "  Agreement Percentage: 74.67%\n",
      "\n",
      "Metrics for Question 10: Does the ad show the brand (logo, brand name) or trademark (something that most people know is the brand) multiple times?\n",
      "  Precision: 0.85\n",
      "  Recall: 0.99\n",
      "  F1 Score: 0.91\n",
      "  Agreement Percentage: 84.00%\n",
      "\n",
      "Metrics for Question 11: Does the ad show the brand or trademark exactly once at the end of the ad?\n",
      "  Precision: 0.87\n",
      "  Recall: 0.60\n",
      "  F1 Score: 0.71\n",
      "  Agreement Percentage: 56.67%\n",
      "\n",
      "Metrics for Question 12: Is the ad intended to affect the viewer emotionally, either with positive emotion (fun, joy), negative emotion (sad, anxious) or another type of emotion? (Note: You may not personally agree, but assess if that was the intention.)\n",
      "  Precision: 0.86\n",
      "  Recall: 0.98\n",
      "  F1 Score: 0.92\n",
      "  Agreement Percentage: 84.67%\n",
      "\n",
      "Metrics for Question 13: Does the ad give you a positive feeling about the brand?\n",
      "  Precision: 0.85\n",
      "  Recall: 0.89\n",
      "  F1 Score: 0.87\n",
      "  Agreement Percentage: 76.67%\n",
      "\n",
      "Metrics for Question 14: Does the ad have a story arc, with a beginning and an end?\n",
      "  Precision: 0.27\n",
      "  Recall: 0.95\n",
      "  F1 Score: 0.42\n",
      "  Agreement Percentage: 32.67%\n",
      "\n",
      "Metrics for Question 15: Does the ad have a reversal of fortune, where something changes for the better, or changes for the worse?\n",
      "  Precision: 0.23\n",
      "  Recall: 0.35\n",
      "  F1 Score: 0.27\n",
      "  Agreement Percentage: 75.33%\n",
      "\n",
      "Metrics for Question 16: Does the ad have relatable characters?\n",
      "  Precision: 0.51\n",
      "  Recall: 1.00\n",
      "  F1 Score: 0.68\n",
      "  Agreement Percentage: 51.33%\n",
      "\n",
      "Metrics for Question 17: Is the ad creative/clever?\n",
      "  Precision: 0.64\n",
      "  Recall: 0.93\n",
      "  F1 Score: 0.76\n",
      "  Agreement Percentage: 62.67%\n",
      "\n",
      "Metrics for Question 18: Is the ad intended to be funny? (Note: You may not personally agree, but assess if that was the intention.)\n",
      "  Precision: 0.29\n",
      "  Recall: 0.94\n",
      "  F1 Score: 0.44\n",
      "  Agreement Percentage: 50.67%\n",
      "\n",
      "Metrics for Question 19: Does this ad provide sensory stimulation (e.g., cool visuals, arousing music, mouth-watering)?\n",
      "  Precision: 0.59\n",
      "  Recall: 0.93\n",
      "  F1 Score: 0.72\n",
      "  Agreement Percentage: 58.00%\n",
      "\n",
      "Metrics for Question 20: Is the ad visually pleasing?\n",
      "  Precision: 0.73\n",
      "  Recall: 0.91\n",
      "  F1 Score: 0.81\n",
      "  Agreement Percentage: 69.33%\n",
      "\n",
      "Metrics for Question 21: Does the ad have cute elements like animals, babies, animated characters, etc?\n",
      "  Precision: 0.36\n",
      "  Recall: 0.71\n",
      "  F1 Score: 0.48\n",
      "  Agreement Percentage: 65.33%\n",
      "\n",
      "Overall Agreement Percentage: 63.90%\n"
     ]
    }
   ],
   "source": [
    "# Load the predicted answers and ground truth values\n",
    "predicted_df = pd.read_csv('results_labeled.csv')\n",
    "ground_truth_df = pd.read_csv('ground_truth_file.csv')\n",
    "\n",
    "# Rename the ID column in ground_truth_df to match predicted_df\n",
    "ground_truth_df.rename(columns={'creative_data_id': 'video_id'}, inplace=True)\n",
    "\n",
    "# Get the list of remaining columns from the 2nd column onwards\n",
    "remaining_columns = predicted_df.columns[1:]\n",
    "\n",
    "# Create new column names for the predicted DataFrame\n",
    "new_column_names = [f'question_{i+1}' for i in range(len(remaining_columns))]\n",
    "\n",
    "# Rename the remaining columns in the predicted DataFrame\n",
    "predicted_df.rename(columns=dict(zip(remaining_columns, new_column_names)), inplace=True)\n",
    "\n",
    "# Rename the corresponding columns in the ground truth DataFrame\n",
    "ground_truth_df.rename(columns=dict(zip(remaining_columns, new_column_names)), inplace=True)\n",
    "assert (predicted_df.columns == ground_truth_df.columns).all(), \"Columns do not match\"\n",
    "assert (predicted_df['video_id'] == ground_truth_df['video_id']).all(), \"Video IDs do not match\"\n",
    "\n",
    "# Extract the question columns, skipping the 'video_id' column\n",
    "questions = predicted_df.columns[1:]  # All columns except 'video_id'\n",
    "\n",
    "# Define the list of questions corresponding to the columns\n",
    "questions_list = [\n",
    "    \"Is there a call to go online (e.g., shop online, visit the Web)?\",\n",
    "    \"Is online contact information provided (e.g., URL, website)?\",\n",
    "    \"Is there a visual or verbal call to purchase (e.g., buy now, order now)?\",\n",
    "    \"Does the ad portray a sense of urgency to act (e.g., buy before sales end, order before it ends)?\",\n",
    "    \"Is there an incentive to buy (e.g., a discount, a coupon, a sale, or 'limited time offer')?\",\n",
    "    \"Is offline contact information provided (e.g., phone, mail, store location)?\",\n",
    "    \"Is there mention of something free?\",\n",
    "    \"Does the ad mention at least one specific product or service (e.g., model, type, item)?\",\n",
    "    \"Is there any verbal or visual mention of the price?\",\n",
    "    \"Does the ad show the brand (logo, brand name) or trademark (something that most people know is the brand) multiple times?\",\n",
    "    \"Does the ad show the brand or trademark exactly once at the end of the ad?\",\n",
    "    \"Is the ad intended to affect the viewer emotionally, either with positive emotion (fun, joy), negative emotion (sad, anxious) or another type of emotion? (Note: You may not personally agree, but assess if that was the intention.)\",\n",
    "    \"Does the ad give you a positive feeling about the brand?\",\n",
    "    \"Does the ad have a story arc, with a beginning and an end?\",\n",
    "    \"Does the ad have a reversal of fortune, where something changes for the better, or changes for the worse?\",\n",
    "    \"Does the ad have relatable characters?\",\n",
    "    \"Is the ad creative/clever?\",\n",
    "    \"Is the ad intended to be funny? (Note: You may not personally agree, but assess if that was the intention.)\",\n",
    "    \"Does this ad provide sensory stimulation (e.g., cool visuals, arousing music, mouth-watering)?\",\n",
    "    \"Is the ad visually pleasing?\",\n",
    "    \"Does the ad have cute elements like animals, babies, animated characters, etc?\"\n",
    "]\n",
    "\n",
    "# Initialize variables for overall metrics\n",
    "total_agreements = 0\n",
    "total_comparisons = 0\n",
    "\n",
    "# Iterate over each question column\n",
    "for i, question in enumerate(questions):\n",
    "    # Extract the predicted and true values for the current question\n",
    "    y_pred = predicted_df[question].map({'Yes': 1, 'No': 0}).values\n",
    "    y_true = ground_truth_df[question].map({'Yes': 1, 'No': 0}).values\n",
    "    \n",
    "    # Calculate metrics for the current question\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate the number of agreements for the current question\n",
    "    agreements = (y_pred == y_true).sum()\n",
    "    total_agreements += agreements\n",
    "    total_comparisons += len(y_pred)\n",
    "    \n",
    "    # Print the scores for the current question\n",
    "    print(f\"Metrics for Question {i+1}: {questions_list[i]}\")\n",
    "    print(f\"  Precision: {precision:.2f}\")\n",
    "    print(f\"  Recall: {recall:.2f}\")\n",
    "    print(f\"  F1 Score: {f1:.2f}\")\n",
    "    print(f\"  Agreement Percentage: {(agreements / len(y_pred)) * 100:.2f}%\")\n",
    "    print()\n",
    "\n",
    "# Calculate the overall agreement percentage\n",
    "overall_agreement_percentage = (total_agreements / total_comparisons) * 100\n",
    "\n",
    "# Print the overall agreement percentage\n",
    "print(f\"Overall Agreement Percentage: {overall_agreement_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "467242e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('results_labeled.csv')\n",
    "\n",
    "# Rename specific columns\n",
    "df.rename(columns={\n",
    "    df.columns[0]: 'creative_data_id',\n",
    "    df.columns[1]: 'Is there a call to go online (e.g., shop online, visit the Web)?',\n",
    "    df.columns[2]: 'Is online contact information provided (e.g., URL, website)?',\n",
    "    df.columns[3]: 'Is there a visual or verbal call to purchase (e.g., buy now, order now)?',\n",
    "    df.columns[4]: 'Does the ad portray a sense of urgency to act (e.g., buy before sales end, order before it ends)?',\n",
    "    df.columns[5]: 'Is there an incentive to buy (e.g., a discount, a coupon, a sale, or \"limited time offer\")?',\n",
    "    df.columns[6]: 'Is offline contact information provided (e.g., phone, mail, store location)?',\n",
    "    df.columns[7]: 'Is there mention of something free?',\n",
    "    df.columns[8]: 'Does the ad mention at least one specific product or service (e.g., model, type, item)?',\n",
    "    df.columns[9]: 'Is there any verbal or visual mention of the price?',\n",
    "    df.columns[10]: 'Does the ad show the brand (logo, brand name) or trademark (something that most people know is the brand) multiple times?',\n",
    "    df.columns[11]: 'Does the ad show the brand or trademark exactly once at the end of the ad?',\n",
    "    df.columns[12]: 'Is the ad intended to affect the viewer emotionally, either with positive emotion (fun, joy), negative emotion (sad, anxious) or another type of emotion? (Note: You may not personally agree, but assess if that was the intention.)',\n",
    "    df.columns[13]: 'Does the ad give you a positive feeling about the brand?',\n",
    "    df.columns[14]: 'Does the ad have a story arc, with a beginning and an end?',\n",
    "    df.columns[15]: 'Does the ad have a reversal of fortune, where something changes for the better, or changes for the worse?',\n",
    "    df.columns[16]: 'Does the ad have relatable characters?',\n",
    "    df.columns[17]: 'Is the ad creative/clever?',\n",
    "    df.columns[18]: 'Is the ad intended to be funny? (Note: You may not personally agree, but assess if that was the intention.)',\n",
    "    df.columns[19]: 'Does this ad provide sensory stimulation (e.g., cool visuals, arousing music, mouth-watering)?',\n",
    "    df.columns[20]: 'Is the ad visually pleasing?',\n",
    "    df.columns[21]: 'Does the ad have cute elements like animals, babies, animated characters, etc?'\n",
    "}, inplace=True)\n",
    "\n",
    "# Save the changes to a new CSV file\n",
    "df.to_csv('raut.kar_answers.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb6f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
